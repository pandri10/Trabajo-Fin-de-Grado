{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import xarray as xr\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import joblib\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_md = \"\"\"\n",
    "# Demo TFG - Aprendizaje Automático con Datos Meteorológicos\n",
    "\n",
    "Bienvenido/a a la demo interactiva del Trabajo de Fin de Grado.\n",
    "\n",
    "Este entorno ha sido desarrollado como parte de la presentación del TFG y permite explorar el funcionamiento de los modelos o soluciones propuestas de forma interactica.\n",
    "\n",
    "## Estructura de la demo\n",
    "\n",
    "La aplicación cuenta con tres pestañas principales:\n",
    "\n",
    "- **Home:** Esta explicación general.\n",
    "- **Cuestión 1:** Demostración interactiva relacionada con un Modelo de Regresión de la parte de Modelos Tradicionales.\n",
    "- **Cuestión 2:** Demostración correspondiente a un Modelos de Red Neuronal de la parte de Aplicación de Redes Neuronales.\n",
    "\n",
    "---\n",
    "\n",
    "> *Desarrollado por Adriana Gordillo Melero, Universidad de Sevilla, 2025*\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_md= \"\"\"\n",
    "# Aplicación de Modelo de Regresión en Datos Tabulares\n",
    "\n",
    "En esta pestaña se verá la aplicación del modelo XGBoost para la predicción del número de rayos.\n",
    "\n",
    "Para ello se presenta una pequeña muestra del dataset para poder realizar predicciones con la entrada seleccionada.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_md = \"\"\"\n",
    "# Aplicación de U-Net para Predicción de rayos sobre píxeles de la Imagen\n",
    "\n",
    "En esta pestaña se verá la aplicación del modelo de U-Net para la predicción de la probabilidad de existencia de un rayo sobre cada píxel de una imagen.\n",
    "\n",
    "Para ello se presenta dos pestañas donde se cargarán las entradas de la Red y la salida original de dischos datos de forma respectiva.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colores y diseño interfaz:\n",
    "theme = gr.themes.Soft(primary_hue=\"blue\").set(\n",
    "    body_background_fill=\"#1e1e1e\",\n",
    "    body_text_color=\"#d4d4d4\",\n",
    "    input_background_fill=\"#2c2c2c\",\n",
    "    panel_background_fill=\"#2c2c2c\",\n",
    ")\n",
    "\n",
    "# CSS adicional para forzar texto negro en dataframes\n",
    "custom_css = \"\"\"\n",
    "/* Fuerza texto negro en celdas de Dataframe */\n",
    ".gradio-container .dataframe td,\n",
    ".gradio-container .dataframe th {\n",
    "    color: #000 !important;\n",
    "}\n",
    "\n",
    "/* Fondo y borde del dataframe */\n",
    ".gradio-container .dataframe {\n",
    "    background-color: #f8f9fa !important;\n",
    "    border: 1px solid #ced4da !important;\n",
    "}\n",
    ".gradio-container .dataframe td,\n",
    ".gradio-container .dataframe th,\n",
    ".gradio-container .dataframe-input td,\n",
    ".gradio-container .dataframe-input th {\n",
    "    color: black !important;\n",
    "}\n",
    "\n",
    ".gradio-container .dataframe,\n",
    ".gradio-container .dataframe-input {\n",
    "    background-color: #f8f9fa !important;\n",
    "    border: 1px solid #ced4da !important;\n",
    "}\n",
    "\n",
    "/* Estilo específico para el DataFrame con ID selector-df */\n",
    "#selector-df td,\n",
    "#selector-df th {\n",
    "    color: black !important;\n",
    "}\n",
    "#selector-df {\n",
    "    background-color: #f8f9fa !important;\n",
    "    border: 1px solid #ced4da !important;\n",
    "}\n",
    "\n",
    "/* Cambia el fondo del label para el selector */\n",
    "#selector-df label {\n",
    "    background-color: transparent !important;\n",
    "    color: #d4d4d4 !important;\n",
    "    padding: 4px 0;\n",
    "}\n",
    "/* Elimina fondo blanco del label del componente selector-df */\n",
    "#selector-df > div:first-child {\n",
    "    background-color: transparent !important;\n",
    "    color: #d4d4d4 !important;\n",
    "    padding: 4px 0;\n",
    "}\n",
    "#selector-df .label {\n",
    "    background-color: transparent !important;\n",
    "    color: #d4d4d4 !important;\n",
    "    font-weight: bold;\n",
    "}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\pickle.py:1718: UserWarning: [17:16:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\../common/error_msg.h:82: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  setstate(state)\n"
     ]
    }
   ],
   "source": [
    "# Cuestión 1\n",
    "salidas = pd.read_csv(\"examples/salidas_reg10.csv\", header=None)\n",
    "df_c1 = pd.read_csv(\"examples/entradas_reg10.csv\", header=None)\n",
    "xgb_model_path = \"models/modelo_xgboost_reg.pkl\"\n",
    "xgb_model = joblib.load(xgb_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuestión 2\n",
    "modelo_c2 = load_model('models/modelo_u_net_clas.h5') # quita el compile false en tu versión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://04a6fca220caf6afc9.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://04a6fca220caf6afc9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 272ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_24024\\1999349219.py\", line 88, in actualizar_salida\n",
      "    df = mostrar_datos_npy(file)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_24024\\1999349219.py\", line 69, in mostrar_datos_npy\n",
      "    data = np.load(file)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 427, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_24024\\1999349219.py\", line 42, in mostrar_imagen_npy\n",
      "    example = load_npy_file(file)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_24024\\1999349219.py\", line 27, in load_npy_file\n",
      "    return np.load(file.name)\n",
      "AttributeError: 'NoneType' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_24024\\1999349219.py\", line 42, in mostrar_imagen_npy\n",
      "    example = load_npy_file(file)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_24024\\1999349219.py\", line 27, in load_npy_file\n",
      "    return np.load(file.name)\n",
      "AttributeError: 'NoneType' object has no attribute 'name'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_24024\\1999349219.py\", line 88, in actualizar_salida\n",
      "    df = mostrar_datos_npy(file)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_24024\\1999349219.py\", line 69, in mostrar_datos_npy\n",
      "    data = np.load(file)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 427, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import math\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar datos\n",
    "salidas = pd.read_csv(\"examples/salidas_reg10.csv\", header=None)\n",
    "df_c1 = pd.read_csv(\"examples/entradas_reg10.csv\", header=None)\n",
    "xgb_model_path = \"models/modelo_xgboost_reg.pkl\"\n",
    "xgb_model = joblib.load(xgb_model_path)\n",
    "\n",
    "# Función para Cuestión 1\n",
    "def estimar_cuestion1(df_predict: pd.DataFrame, index: float) -> str:\n",
    "    y_pred = xgb_model.predict(df_predict)\n",
    "    index = int(index)\n",
    "    valor_real = salidas.iloc[index, 0]\n",
    "    text = f\"Número real de rayos en la imagen: {valor_real}\\n\"\n",
    "    text += f\"Número de rayos predecidos por el modelo: {math.ceil(y_pred[0])}\"\n",
    "    return text\n",
    "\n",
    "# Funciones para Cuestión 2\n",
    "def load_npy_file(file):\n",
    "    return np.load(file.name)\n",
    "\n",
    "def estimar_cuestion2(file: gr.File):\n",
    "    example = load_npy_file(file)\n",
    "    resultado = modelo_c2.predict(example)[0]\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(resultado)\n",
    "    ax.axis('off')\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    return Image.open(buf)\n",
    "\n",
    "def mostrar_imagen_npy(file):\n",
    "    example = load_npy_file(file)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(example[0])\n",
    "    ax.axis('off')\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    return Image.open(buf)\n",
    "\n",
    "def mostrar_datos_npy_con_canal(file, canal):\n",
    "    try:\n",
    "        data = np.load(file.name)[0]\n",
    "        if data.ndim == 3 and data.shape[-1] > 1:\n",
    "            if 0 <= canal < data.shape[-1]:\n",
    "                matriz = data[:, :, canal]\n",
    "            else:\n",
    "                return pd.DataFrame([[\"Canal fuera de rango.\"]])\n",
    "        elif data.ndim == 2 or (data.ndim == 3 and data.shape[-1] == 1):\n",
    "            matriz = data[:, :, 0] if data.ndim == 3 else data\n",
    "        else:\n",
    "            return pd.DataFrame([[\"Formato no soportado.\"]])\n",
    "        return pd.DataFrame(matriz)\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame([[\"Error:\", str(e)]])\n",
    "\n",
    "def mostrar_datos_npy(file):\n",
    "    data = np.load(file)\n",
    "    return pd.DataFrame(data[0])\n",
    "\n",
    "# # Interfaz Gradio\n",
    "\n",
    "\n",
    "def estilo_negro(df):\n",
    "    return df.style.set_properties(**{'color': 'black'})\n",
    "\n",
    "def actualizar_fila(evt: gr.SelectData):\n",
    "    index = evt.index[0]\n",
    "    return estilo_negro(df_c1.iloc[[index]]), index\n",
    "\n",
    "def actualizar_entrada(file, canal_str):\n",
    "    canal = int(canal_str)\n",
    "    df = mostrar_datos_npy_con_canal(file, canal)\n",
    "    return estilo_negro(df)\n",
    "\n",
    "def actualizar_salida(file):\n",
    "    df = mostrar_datos_npy(file)\n",
    "    return estilo_negro(df)\n",
    "\n",
    "demo = gr.Blocks(\n",
    "    theme=theme, css=custom_css,\n",
    "    title=\"TFG Demo\"\n",
    ")\n",
    "\n",
    "with demo:\n",
    "    with gr.Tabs():\n",
    "        with gr.Tab(\"Home\"):\n",
    "            gr.Markdown(home_md)\n",
    "\n",
    "        with gr.Tab(\"Cuestión 1\"):\n",
    "            gr.Markdown(c1_md)\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    df_selector = gr.DataFrame(\n",
    "                        value=df_c1,\n",
    "                        col_count=df_c1.shape[1],\n",
    "                        interactive=True,\n",
    "                        label=\"Selecciona una fila del dataset\",\n",
    "                        type=\"pandas\",\n",
    "                        elem_id=\"selector-df\"\n",
    "                    )\n",
    "\n",
    "\n",
    "                    selected_row = gr.DataFrame(\n",
    "                        value=estilo_negro(df_c1.iloc[[0]]),\n",
    "                        col_count=df_c1.shape[1],\n",
    "                        interactive=False,\n",
    "                        label=\"Fila seleccionada para predecir\",\n",
    "                        type=\"pandas\"\n",
    "                    )\n",
    "\n",
    "                    selected_index = gr.Number(visible=False)\n",
    "\n",
    "                with gr.Column():\n",
    "                    output_c1 = gr.Textbox(label=\"Resultado de la predicción\", lines=4)\n",
    "                    with gr.Row(variant='panel'):\n",
    "                        predict_btn = gr.Button(\"Predecir\")\n",
    "                        predict_btn.click(\n",
    "                            fn=estimar_cuestion1,\n",
    "                            inputs=[selected_row, selected_index],\n",
    "                            outputs=output_c1\n",
    "                        )\n",
    "\n",
    "            df_selector.select(fn=actualizar_fila, inputs=None, outputs=[selected_row, selected_index])\n",
    "\n",
    "        with gr.Tab(\"Cuestión 2\"):\n",
    "            gr.Markdown(c2_md)\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    file_input1 = gr.File(label=\"Sube tus entradas del modelo (.npy)\", file_types=[\".npy\"], file_count=\"single\")\n",
    "                    file_input2 = gr.File(label=\"Sube tu archivo salida original (.npy)\", file_types=[\".npy\"], file_count=\"single\")\n",
    "\n",
    "                    canal_selector = gr.Dropdown(\n",
    "                        choices=[\"0\", \"1\", \"2\", \"3\"],\n",
    "                        label=\"Selecciona el canal del predictor\",\n",
    "                        value=\"0\"\n",
    "                    )\n",
    "\n",
    "                    gr.Markdown(\"#### Matrices cargadas\")\n",
    "                    with gr.Row():\n",
    "                        data_input1 = gr.DataFrame(label=\"Canal seleccionado\", interactive=False)\n",
    "                        data_input2 = gr.DataFrame(label=\"Salida original\", interactive=False)\n",
    "\n",
    "                with gr.Column(scale=1):\n",
    "                    imagen_mostrada = gr.Image(label=\"Vista previa del modelo\")\n",
    "                    output_image = gr.Image(label=\"Imagen generada por el modelo\")\n",
    "                    with gr.Row(variant='panel'):\n",
    "                        predict_btn2 = gr.Button(\"Predecir\")\n",
    "                        predict_btn2.click(fn=estimar_cuestion2, inputs=[file_input1], outputs=output_image)\n",
    "\n",
    "            file_input1.change(fn=actualizar_entrada, inputs=[file_input1, canal_selector], outputs=[data_input1])\n",
    "            canal_selector.change(fn=actualizar_entrada, inputs=[file_input1, canal_selector], outputs=[data_input1])\n",
    "            file_input2.change(fn=actualizar_salida, inputs=[file_input2], outputs=[data_input2])\n",
    "            file_input2.change(fn=mostrar_imagen_npy, inputs=[file_input2], outputs=[imagen_mostrada])\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
